// <copyright file="Pagination.cs" company="DECTech.Tokyo">
// Copyright (c) DECTech.Tokyo. All rights reserved.
// </copyright>

/*
 * Crawler API
 *
 * API for crawling web pages and searching in crowled result
 *
 * OpenAPI spec version: 1.0.0
 * Contact: zakhar_amirov@dectech.tokyo
 * Generated by: https://github.com/swagger-api/swagger-codegen.git
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

namespace CrawlerApi.Models
{
    using System;
    using System.Runtime.Serialization;
    using System.Text;
    using JetBrains.Annotations;
    using Microsoft.AspNetCore.Mvc;
    using Newtonsoft.Json;

    /// <summary>
    /// paging request parameters
    /// </summary>
    [DataContract]
    [UsedImplicitly]
    public class Pagination : IEquatable<Pagination>
    {
        /// <summary>
        /// Initializes a new instance of the <see cref="Pagination"/> class.
        /// </summary>
        public Pagination()
        {
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="Pagination" /> class.
        /// </summary>
        /// <param name="pageSize">number of items to return in one request. if missing returns 10 items..</param>
        /// <param name="requestId">id of paged request to keep paging between requests. if missing starts new request..</param>
        public Pagination(int? pageSize = null, string requestId = null)
        {
            PageSize = pageSize;
            RequestId = requestId;
        }

        /// <summary>
        /// Gets number of items to return in one request. if missing returns 10 items.
        /// </summary>
        [FromQuery(Name = "pagesize")]
        public int? PageSize { get; }

        /// <summary>
        /// Gets id of paged request to keep paging between requests. if missing starts new request.
        /// </summary>
        [FromQuery(Name = "requestId")]
        public string RequestId { get; }

        /// <summary>Compare objects equality</summary>
        /// <param name="left">Left part of expression.</param>
        /// <param name="right">Right part of expression.</param>
        public static bool operator ==(Pagination left, Pagination right)
        {
            return Equals(left, right);
        }

        /// <summary>Compare objects unequality</summary>
        /// <param name="left">Left part of expression.</param>
        /// <param name="right">Right part of expression.</param>
        public static bool operator !=(Pagination left, Pagination right)
        {
            return !Equals(left, right);
        }

        /// <summary>
        /// Returns true if objects are equal
        /// </summary>
        /// <param name="obj">Object to be compared</param>
        /// <returns>Boolean</returns>
        public override bool Equals(object obj)
        {
            if (ReferenceEquals(null, obj))
            {
                return false;
            }

            if (ReferenceEquals(this, obj))
            {
                return true;
            }

            if (obj.GetType() != GetType())
            {
                return false;
            }

            return Equals((Pagination)obj);
        }

        /// <summary>
        /// Returns true if Page instances are equal
        /// </summary>
        /// <param name="other">Instance of Page to be compared</param>
        /// <returns>Boolean</returns>
        public bool Equals(Pagination other)
        {
            if (ReferenceEquals(null, other))
            {
                return false;
            }

            if (ReferenceEquals(this, other))
            {
                return true;
            }

            return
                (
                    (PageSize == other.PageSize) ||
                    ((PageSize != null) &&
                     PageSize.Equals(other.PageSize))) &&
                (
                    (RequestId == other.RequestId) ||
                    ((RequestId != null) &&
                     RequestId.Equals(other.RequestId)));
        }

        /// <summary>
        /// Gets the hash code
        /// </summary>
        /// <returns>Hash code</returns>
        public override int GetHashCode()
        {
            // credit: http://stackoverflow.com/a/263416/677735
            unchecked
            {
                var hash = 41;

                // Suitable nullity checks etc, of course :)
                if (PageSize != null)
                {
                    hash = (hash * 59) + PageSize.GetHashCode();
                }

                if (RequestId != null)
                {
                    hash = (hash * 59) + RequestId.GetHashCode();
                }

                return hash;
            }
        }

        /// <summary>
        /// Returns the JSON string presentation of the object
        /// </summary>
        /// <returns>JSON string presentation of the object</returns>
        public string ToJson()
        {
            return JsonConvert.SerializeObject(this, Formatting.Indented);
        }

        /// <summary>
        /// Returns the string presentation of the object
        /// </summary>
        /// <returns>String presentation of the object</returns>
        public override string ToString()
        {
            var sb = new StringBuilder();
            sb.Append("class Page {\n");
            sb.Append("  PageSize: ").Append(PageSize).Append("\n");
            sb.Append("  RequestId: ").Append(RequestId).Append("\n");
            sb.Append("}\n");
            return sb.ToString();
        }
    }
}